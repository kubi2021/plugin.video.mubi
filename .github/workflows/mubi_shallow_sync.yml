name: Mubi Shallow Sync (Fast)

on:
  schedule:
    - cron: '0 12 * * 2,4,6' # Every Tuesday, Thursday, Saturday at 12:00 UTC
  workflow_dispatch:

permissions:
  contents: write

jobs:
  update-catalog:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11' 

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        if [ -f backend/requirements.txt ]; then pip install -r backend/requirements.txt; fi

    - name: Run Scraper (Shallow Mode)
      run: |
        # Create database directory
        mkdir -p database/v1
        
        # Fetch films.json (gzipped) from database branch to use as input for greedy algorithm
        # We need to decompress it first because the scraper expects raw JSON
        wget https://raw.githubusercontent.com/${{ github.repository }}/database/v1/films.json.gz -O backend/previous_films.json.gz
        gzip -d backend/previous_films.json.gz
        
        wget https://raw.githubusercontent.com/${{ github.repository }}/database/v1/series.json.gz -O database/v1/series.json.gz
        gzip -d database/v1/series.json.gz

        # Run scraper in SHALLOW mode with input
        # Note: series input is inferred from --series-output existence
        python backend/scraper.py --mode shallow --output database/v1/films.json --series-output database/v1/series.json --input backend/previous_films.json
        
    - name: Enrich Metadata (Add IMDB/TMDB IDs)
      env:
        TMDB_API_KEY: ${{ secrets.TMDB_API_KEY }}
      run: |
        python backend/enrich_metadata.py --path database/v1/films.json
        python backend/enrich_metadata.py --path database/v1/series.json --type series

    - name: Generate Repo Files (Compress & Hash)
      run: |
        cd database/v1
        python ../../backend/generate_repo.py --file films.json
        python ../../backend/generate_repo.py --file series.json
        
        # Verify output
        ls -la

    - name: Validate Schema
      run: |
        pip install jsonschema
        python backend/validate_schema.py --path database/v1/films.json --version 1
        python backend/validate_schema.py --path database/v1/series.json --version 1

    - name: Deploy to Database Branch
      uses: JamesIves/github-pages-deploy-action@v4
      with:
        branch: database # The branch the action should deploy to.
        folder: database # The folder the action should deploy.
        clean: true # Automatically remove deleted files from the deploy branch
        force: true # Force push to ignore history (orphan-like behavior)

    - name: Notify on Failure
      if: failure()
      uses: actions/github-script@v6
      with:
        script: |
          const { repo, owner } = context.repo;
          const run_url = `https://github.com/${owner}/${repo}/actions/runs/${context.runId}`;
          
          await github.rest.issues.create({
            owner,
            repo,
            title: `ðŸš¨ Scraper Failed: Shallow Sync`,
            body: `The scheduled shallow sync failed.\n\n[View Run logs](${run_url})\n\nPlease check the logs for 429 errors or API changes.`
          });
