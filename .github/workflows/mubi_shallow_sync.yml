name: Mubi Shallow Sync (Fast)

on:
  schedule:
    - cron: '0 12 * * 2,4,6' # Every Tuesday, Thursday, Saturday at 12:00 UTC
  workflow_dispatch:

permissions:
  contents: write

jobs:
  update-catalog:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11' 

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        if [ -f backend/requirements.txt ]; then pip install -r backend/requirements.txt; fi

    - name: Install VPN Dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y wireguard

    - name: Connect to ProtonVPN (WireGuard)
      continue-on-error: true
      run: |
        echo "Processing WireGuard config..."
        echo "${{ secrets.PROTON_WG_CONFIG }}" > wg0.conf
        # Access DNS line to prevent resolvconf dependency issues in CI
        sed -i '/^DNS/d' wg0.conf
        chmod 600 wg0.conf
        
        echo "Checking initial IP..."
        curl -s --max-time 10 ifconfig.me || echo "Failed to check IP"
        
        echo "Starting VPN..."
        if sudo wg-quick up ./wg0.conf; then
          echo "‚úÖ VPN Connection SUCCESS"
          echo "Waiting for connection stability..."
          sleep 5
          echo "Waiting for connection stability..."
          sleep 5
          echo "Checking VPN IP..."
          curl -s --max-time 10 ifconfig.me || echo "Failed to check IP"
        else
          echo "‚ö†Ô∏è VPN Connection FAILED - Proceeding without VPN"
          exit 1
        fi

    - name: Checkout Database Branch (Input)
      uses: actions/checkout@v4
      with:
        ref: database
        path: backend/history
        fetch-depth: 1

    - name: Prepare Input Files
      run: |
        # Create database directory
        mkdir -p database/v1
        
        echo "DEBUG: Checking history directory..."
        ls -la backend/history/v1/ || echo "backend/history/v1 not found"
        
        # Fetch films.json (gzipped) from downloaded branch history
        if [ -f backend/history/v1/films.json.gz ]; then
            echo "DEBUG: Found films.json.gz in history."
            cp backend/history/v1/films.json.gz backend/previous_films.json.gz
            gzip -d backend/previous_films.json.gz
            
            echo "DEBUG: Decompressed previous_films.json. Head content:"
            head -n 20 backend/previous_films.json
        else
            echo "CRITICAL: No films.json found in database branch!"
            exit 1
        fi
        
        if [ -f backend/history/v1/series.json.gz ]; then
            cp backend/history/v1/series.json.gz database/v1/series.json.gz
            gzip -d database/v1/series.json.gz
        else
             echo "Warning: series.json not found."
        fi

        # Run scraper in SHALLOW mode with input
        # Note: series input is inferred from --series-output existence
        python backend/scraper.py --mode shallow --output database/v1/films.json --series-output database/v1/series.json --input backend/previous_films.json
        

        
    - name: Enrich Metadata (Add IMDB/TMDB IDs)
      env:
        TMDB_API_KEY: ${{ secrets.TMDB_API_KEY }}
        OMDB_API_KEYS: ${{ secrets.OMDB_API_KEYS }}
      run: |
        python backend/enrich_metadata.py --path database/v1/films.json
        python backend/enrich_metadata.py --path database/v1/series.json --type series

    - name: Calculate Bayesian Ratings
      run: |
        echo "Running Bayesian Rating Calculator..."
        if [ -f backend/previous_films.json ]; then
            python backend/rating_calculator.py database/v1/films.json --history-file backend/previous_films.json
        else
            python backend/rating_calculator.py database/v1/films.json
        fi
        python backend/rating_calculator.py database/v1/series.json


    - name: Generate Repo Files (Compress & Hash)
      run: |
        cd database/v1
        python ../../backend/generate_repo.py --file films.json
        python ../../backend/generate_repo.py --file series.json
        
        # Verify output
        ls -la

    - name: Validate Schema
      run: |
        pip install jsonschema
        python backend/validate_schema.py --path database/v1/films.json --version 1
        python backend/validate_schema.py --path database/v1/series.json --version 1

    - name: Cleanup Raw JSON (Keep Compressed Only)
      run: |
        rm database/v1/films.json
        rm database/v1/series.json

    - name: Deploy to Database Branch
      uses: JamesIves/github-pages-deploy-action@v4
      with:
        branch: database # The branch the action should deploy to.
        folder: database # The folder the action should deploy.
        clean: true # Automatically remove deleted files from the deploy branch
        force: true # Force push to ignore history (orphan-like behavior)

    - name: Notify on Failure
      if: failure()
      uses: actions/github-script@v6
      with:
        script: |
          const { repo, owner } = context.repo;
          const run_url = `https://github.com/${owner}/${repo}/actions/runs/${context.runId}`;
          
          await github.rest.issues.create({
            owner,
            repo,
            title: `üö® Scraper Failed: Shallow Sync`,
            body: `The scheduled shallow sync failed.\n\n[View Run logs](${run_url})\n\nPlease check the logs for 429 errors or API changes.`
          });
