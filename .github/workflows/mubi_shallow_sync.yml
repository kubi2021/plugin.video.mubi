name: Mubi Shallow Sync (Fast)

on:
  schedule:
    - cron: '0 12 * * 2,4,6' # Every Tuesday, Thursday, Saturday at 12:00 UTC
  workflow_dispatch:

permissions:
  contents: write

jobs:
  update-catalog:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11' 

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        if [ -f backend/requirements.txt ]; then pip install -r backend/requirements.txt; fi



    - name: Install VPN Dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y wireguard-tools openresolv

    - name: Connect to ProtonVPN (WireGuard)
      continue-on-error: true
      run: |
        echo "=== NETWORK DEBUG (BEFORE) ==="
        ip addr
        ip route
        echo "=============================="

        echo "Generating WireGuard config from secrets..."
        cat <<EOF > wg0.conf
        [Interface]
        PrivateKey = ${{ secrets.WIREGUARD_PRIVATE_KEY }}
        Address = ${{ secrets.WIREGUARD_ADDRESS }}
        # DNS = 10.2.0.1  <-- Commented out to prevent resolvconf issues

        [Peer]
        PublicKey = ${{ secrets.WIREGUARD_PUBLIC_KEY }}
        AllowedIPs = 0.0.0.0/0
        Endpoint = ${{ secrets.WIREGUARD_ENDPOINT }}
        PersistentKeepalive = 25
        EOF
        
        chmod 600 wg0.conf
        
        echo "Checking initial IP..."
        curl -s --max-time 10 https://ifconfig.me || echo "Failed to fetch IP"
        
        echo "Starting VPN..."
        if sudo wg-quick up ./wg0.conf; then
          echo "âœ… VPN Interface Returned Success"
          
          echo "=== NETWORK DEBUG (VPN UP) ==="
          sudo wg show
          ip addr
          ip route
          echo "Ping Test (1.1.1.1):"
          ping -c 2 1.1.1.1 || echo "Ping failed"
          echo "=============================="
          
          echo "Waiting for connection stability..."
          sleep 5
          
          echo "Checking VPN IP..."
          if curl -v --max-time 10 https://ifconfig.me; then
             echo "âœ… IP Check Success"
          else
             echo "âŒ IP Check Failed"
             exit 1 
          fi
        else
          echo "âš ï¸ VPN Connection FAILED - Proceeding without VPN"
          exit 1
        fi

    - name: Checkout Database Branch (Input)
      uses: actions/checkout@v4
      with:
        ref: database
        path: backend/history
        fetch-depth: 1

    - name: Prepare Input Files
      run: |
        # Create database directory
        mkdir -p database/v1
        
        echo "DEBUG: Checking history directory..."
        ls -la backend/history/v1/ || echo "backend/history/v1 not found"
        
        # Fetch films.json (gzipped) from downloaded branch history
        if [ -f backend/history/v1/films.json.gz ]; then
            echo "DEBUG: Found films.json.gz in history."
            cp backend/history/v1/films.json.gz backend/previous_films.json.gz
            gzip -d backend/previous_films.json.gz
            
            echo "DEBUG: Decompressed previous_films.json. Head content:"
            head -n 20 backend/previous_films.json
        else
            echo "CRITICAL: No films.json found in database branch!"
            exit 1
        fi
        
        if [ -f backend/history/v1/series.json.gz ]; then
            cp backend/history/v1/series.json.gz database/v1/series.json.gz
            gzip -d database/v1/series.json.gz
        else
             echo "Warning: series.json not found."
        fi

        # Run scraper in SHALLOW mode with input
        # Note: series input is inferred from --series-output existence
        python backend/scraper.py --mode shallow --output database/v1/films.json --series-output database/v1/series.json --input backend/previous_films.json
        

        
    - name: Enrich Metadata (Add IMDB/TMDB IDs)
      env:
        TMDB_API_KEY: ${{ secrets.TMDB_API_KEY }}
        OMDB_API_KEYS: ${{ secrets.OMDB_API_KEYS }}
      run: |
        python backend/enrich_metadata.py --path database/v1/films.json
        python backend/enrich_metadata.py --path database/v1/series.json --type series

    - name: Calculate Bayesian Ratings
      run: |
        echo "Running Bayesian Rating Calculator..."
        if [ -f backend/previous_films.json ]; then
            python backend/rating_calculator.py database/v1/films.json --history-file backend/previous_films.json
        else
            python backend/rating_calculator.py database/v1/films.json
        fi
        python backend/rating_calculator.py database/v1/series.json


    - name: Generate Repo Files (Compress & Hash)
      run: |
        cd database/v1
        python ../../backend/generate_repo.py --file films.json
        python ../../backend/generate_repo.py --file series.json
        
        # Verify output
        ls -la

    - name: Validate Schema
      run: |
        pip install jsonschema
        python backend/validate_schema.py --path database/v1/films.json --version 1
        python backend/validate_schema.py --path database/v1/series.json --version 1

    - name: Cleanup Raw JSON (Keep Compressed Only)
      run: |
        rm database/v1/films.json
        rm database/v1/series.json

    - name: Deploy to Database Branch
      uses: JamesIves/github-pages-deploy-action@v4
      with:
        branch: database # The branch the action should deploy to.
        folder: database # The folder the action should deploy.
        clean: true # Automatically remove deleted files from the deploy branch
        force: true # Force push to ignore history (orphan-like behavior)

    - name: Notify on Failure
      if: failure()
      uses: actions/github-script@v6
      with:
        script: |
          const { repo, owner } = context.repo;
          const run_url = `https://github.com/${owner}/${repo}/actions/runs/${context.runId}`;
          
          await github.rest.issues.create({
            owner,
            repo,
            title: `ðŸš¨ Scraper Failed: Shallow Sync`,
            body: `The scheduled shallow sync failed.\n\n[View Run logs](${run_url})\n\nPlease check the logs for 429 errors or API changes.`
          });
