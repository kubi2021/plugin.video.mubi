name: Mubi Deep Sync (Calibration)

on:
  schedule:
    - cron: '0 12 * * 5' # Every Friday at 12:00 UTC
  workflow_dispatch:

permissions:
  contents: write

jobs:
  deep-sync:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11' 

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        if [ -f backend/requirements.txt ]; then pip install -r backend/requirements.txt; fi

    - name: Run Scraper (Deep Mode)
      run: |
        # Create output directory
        mkdir -p database/v1
        
        # Run scraper in DEEP mode
        python backend/scraper.py --mode deep --output database/v1/films.json --series-output database/v1/series.json
        
    - name: Checkout Database Branch (History)
      uses: actions/checkout@v4
      with:
        ref: database
        path: backend/history
        fetch-depth: 1
        
    - name: Prepare History File
      run: |
        if [ -f backend/history/v1/films.json.gz ]; then
          echo "Found previous database. preparing for warm start..."
          cp backend/history/v1/films.json.gz backend/previous_films.json.gz
          gzip -d backend/previous_films.json.gz
        else
          echo "No previous database found in branch."
        fi
        
    - name: Enrich Metadata (Add IMDB/TMDB IDs)
      env:
        TMDB_API_KEY: ${{ secrets.TMDB_API_KEY }}
        OMDB_API_KEYS: ${{ secrets.OMDB_API_KEYS }}
      run: |
        python backend/enrich_metadata.py --path database/v1/films.json
        python backend/enrich_metadata.py --path database/v1/series.json --type series

    - name: Calculate Bayesian Ratings
      run: |
        echo "Running Bayesian Rating Calculator..."
        if [ -f backend/previous_films.json ]; then
            python backend/rating_calculator.py database/v1/films.json --history-file backend/previous_films.json
        else
            python backend/rating_calculator.py database/v1/films.json
        fi
        python backend/rating_calculator.py database/v1/series.json
        
    - name: Generate Repo Files (Compress & Hash)
      run: |
        cd database/v1
        python ../../backend/generate_repo.py --file films.json
        python ../../backend/generate_repo.py --file series.json
        
        # Verify output
        ls -la

    - name: Validate Schema
      run: |
        pip install jsonschema
        python backend/validate_schema.py --path database/v1/films.json --version 1
        python backend/validate_schema.py --path database/v1/series.json --version 1

    - name: Notify on Failure
      if: failure()
      uses: actions/github-script@v6
      with:
        script: |
          const { repo, owner } = context.repo;
          const run_url = `https://github.com/${owner}/${repo}/actions/runs/${context.runId}`;
          
          await github.rest.issues.create({
            owner,
            repo,
            title: `ðŸš¨ Scraper Failed: Deep Sync`,
            body: `The weekly deep sync failed.\n\n[View Run logs](${run_url})\n\nPlease check the logs for 429 errors or API changes.`
          });

    - name: Cleanup Raw JSON (Keep Compressed Only)
      run: |
        rm database/v1/films.json
        rm database/v1/series.json

    - name: Deploy to Database Branch
      uses: JamesIves/github-pages-deploy-action@v4
      with:
        branch: database # The branch the action should deploy to.
        folder: database # The folder the action should deploy.
        clean: true # Automatically remove deleted files from the deploy branch
        force: true # Force push to ignore history (orphan-like behavior)
