name: Mubi Deep Sync (Calibration)

on:
  schedule:
    - cron: '0 12 * * 5' # Every Friday at 12:00 UTC
  workflow_dispatch:

permissions:
  contents: write

jobs:
  deep-sync:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.11' 

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        if [ -f backend/requirements.txt ]; then pip install -r backend/requirements.txt; fi

    - name: Install VPN Dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y wireguard resolvconf

    - name: Connect to ProtonVPN (WireGuard)
      continue-on-error: true
      run: |
        echo "Creating WireGuard config..."
        echo "${{ secrets.PROTON_WG_CONFIG }}" > wg0.conf
        chmod 600 wg0.conf
        
        echo "Checking initial IP..."
        curl -s ifconfig.me || echo "Failed to check IP"
        
        echo "Starting VPN..."
        if sudo wg-quick up ./wg0.conf; then
          echo "‚úÖ VPN Connection SUCCESS"
          echo "Waiting for connection stability..."
          sleep 5
          echo "Checking VPN IP..."
          curl -s ifconfig.me || echo "Failed to check IP"
        else
          echo "‚ö†Ô∏è VPN Connection FAILED - Proceeding without VPN"
          exit 1
        fi

    - name: Run Scraper (Deep Mode)
      run: |
        # Create output directory
        mkdir -p database/v1
        
        # Run scraper in DEEP mode
        python backend/scraper.py --mode deep --output database/v1/films.json --series-output database/v1/series.json
        
    - name: Checkout Database Branch (History)
      uses: actions/checkout@v4
      with:
        ref: database
        path: backend/history
        fetch-depth: 1
        
    - name: Prepare History File
      run: |
        echo "DEBUG: Checking history directory..."
        ls -la backend/history/v1/ || echo "backend/history/v1/ not found"
        
        if [ -f backend/history/v1/films.json.gz ]; then
          echo "Found previous database. Checking hash..."
          md5sum backend/history/v1/films.json.gz || echo "No md5sum available"
          
          echo "Preparing for warm start..."
          cp backend/history/v1/films.json.gz backend/previous_films.json.gz
          gzip -d backend/previous_films.json.gz
          
          echo "DEBUG: previous_films.json created. Head content:"
          head -n 20 backend/previous_films.json
        else
          echo "No previous database found in branch."
        fi
        


    - name: Enrich Metadata (Add IMDB/TMDB IDs)
      env:
        TMDB_API_KEY: ${{ secrets.TMDB_API_KEY }}
        OMDB_API_KEYS: ${{ secrets.OMDB_API_KEYS }}
      run: |
        python backend/enrich_metadata.py --path database/v1/films.json
        python backend/enrich_metadata.py --path database/v1/series.json --type series

    - name: Calculate Bayesian Ratings
      run: |
        echo "Running Bayesian Rating Calculator..."
        if [ -f backend/previous_films.json ]; then
            python backend/rating_calculator.py database/v1/films.json --history-file backend/previous_films.json
        else
            python backend/rating_calculator.py database/v1/films.json
        fi
        python backend/rating_calculator.py database/v1/series.json
        
    - name: Generate Repo Files (Compress & Hash)
      run: |
        cd database/v1
        python ../../backend/generate_repo.py --file films.json
        python ../../backend/generate_repo.py --file series.json
        
        # Verify output
        ls -la

    - name: Validate Schema
      run: |
        pip install jsonschema
        python backend/validate_schema.py --path database/v1/films.json --version 1
        python backend/validate_schema.py --path database/v1/series.json --version 1

    - name: Notify on Failure
      if: failure()
      uses: actions/github-script@v6
      with:
        script: |
          const { repo, owner } = context.repo;
          const run_url = `https://github.com/${owner}/${repo}/actions/runs/${context.runId}`;
          
          await github.rest.issues.create({
            owner,
            repo,
            title: `üö® Scraper Failed: Deep Sync`,
            body: `The weekly deep sync failed.\n\n[View Run logs](${run_url})\n\nPlease check the logs for 429 errors or API changes.`
          });

    - name: Cleanup Raw JSON (Keep Compressed Only)
      run: |
        rm database/v1/films.json
        rm database/v1/series.json

    - name: Deploy to Database Branch
      uses: JamesIves/github-pages-deploy-action@v4
      with:
        branch: database # The branch the action should deploy to.
        folder: database # The folder the action should deploy.
        clean: true # Automatically remove deleted files from the deploy branch
        force: true # Force push to ignore history (orphan-like behavior)
